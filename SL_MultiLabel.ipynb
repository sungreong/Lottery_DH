{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0d3773b654528d79880d3e2b33a682f0f55f4d8370c8ead39985baabf4eb4f1db",
   "display_name": "Python 3.8.8 64-bit ('test': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./dhlottery_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_nums = np.vstack(data[\"win_nums\"].\\\n",
    "    apply(lambda x : np.array(ast.literal_eval(x))).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_nums_pd = pd.DataFrame(win_nums, columns = [f\"number_{i}\" for i in range(1,7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lottery_num = np.unique(win_nums_pd.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    1    2    3    4    5    6    7    8    9    10  ...   36   37   38   39  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    40   41   42   43   44   45  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 45 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 45 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "pd.DataFrame(np.zeros((1,len(lottery_num))) , columns = lottery_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-11-3ab7204ebc2e>:4: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n  data['Week_Number'] = data['draw_date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "data[\"draw_date\"] = pd.to_datetime(data[\"draw_date\"])\n",
    "data['year'] = pd.DatetimeIndex(data['draw_date']).year\n",
    "data['month'] = pd.DatetimeIndex(data['draw_date']).month\n",
    "data['Week_Number'] = data['draw_date'].dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(lottery_num.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "961\n"
     ]
    }
   ],
   "source": [
    "table = []\n",
    "accumulate_table = pd.DataFrame(np.zeros((1,len(lottery_num))),columns = lottery_num)\n",
    "ratio_table = [accumulate_table]\n",
    "action_table = []\n",
    "for i , one_row in win_nums_pd.iterrows() :\n",
    "    encoding = enc.transform(one_row.values.reshape(-1,1)).toarray().sum(axis=0)\n",
    "    encoding_pd = pd.DataFrame([encoding], columns=lottery_num)\n",
    "    action_table.append(encoding_pd)\n",
    "    accumulate_table = accumulate_table+ encoding_pd\n",
    "    if (i+1) == win_nums_pd.shape[0] : \n",
    "        print(i)\n",
    "        test_table = accumulate_table/(i+1)\n",
    "    else :\n",
    "        ratio_table.append(accumulate_table/(i+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_pd = pd.concat(ratio_table,axis=0).reset_index(drop=True)\n",
    "action_pd = pd.concat(action_table,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            1         2         3         4         5         6         7  \\\n",
       "0    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "957  0.138976  0.130617  0.133751  0.138976  0.133751  0.123302  0.131661   \n",
       "958  0.138831  0.131524  0.133612  0.138831  0.133612  0.123173  0.131524   \n",
       "959  0.139729  0.131387  0.133472  0.138686  0.133472  0.123045  0.131387   \n",
       "960  0.139583  0.132292  0.133333  0.138542  0.133333  0.122917  0.131250   \n",
       "961  0.139438  0.132154  0.133195  0.138398  0.133195  0.122789  0.131113   \n",
       "\n",
       "            8         9        10  ...        39        40        41  \\\n",
       "0    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1    0.000000  0.000000  1.000000  ...  0.000000  1.000000  0.000000   \n",
       "2    0.000000  0.500000  0.500000  ...  0.000000  0.500000  0.000000   \n",
       "3    0.000000  0.333333  0.333333  ...  0.000000  0.333333  0.000000   \n",
       "4    0.000000  0.250000  0.250000  ...  0.000000  0.500000  0.000000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "957  0.133751  0.104493  0.138976  ...  0.143156  0.144201  0.123302   \n",
       "958  0.133612  0.105428  0.139875  ...  0.143006  0.144050  0.123173   \n",
       "959  0.133472  0.105318  0.139729  ...  0.142857  0.144943  0.124088   \n",
       "960  0.133333  0.105208  0.139583  ...  0.142708  0.144792  0.123958   \n",
       "961  0.133195  0.105099  0.139438  ...  0.142560  0.144641  0.123829   \n",
       "\n",
       "           42        43        44        45  year  month  Week_Number  \n",
       "0    0.000000  0.000000  0.000000  0.000000  2002     12           49  \n",
       "1    0.000000  0.000000  0.000000  0.000000  2002     12           50  \n",
       "2    0.500000  0.000000  0.000000  0.000000  2002     12           51  \n",
       "3    0.333333  0.000000  0.000000  0.000000  2002     12           52  \n",
       "4    0.500000  0.000000  0.000000  0.000000  2003      1            1  \n",
       "..        ...       ...       ...       ...   ...    ...          ...  \n",
       "957  0.129572  0.147335  0.132706  0.138976  2021      4           14  \n",
       "958  0.129436  0.147182  0.132568  0.138831  2021      4           15  \n",
       "959  0.129301  0.147028  0.132430  0.138686  2021      4           16  \n",
       "960  0.129167  0.146875  0.132292  0.139583  2021      5           17  \n",
       "961  0.130073  0.146722  0.132154  0.139438  2021      5           18  \n",
       "\n",
       "[962 rows x 48 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>year</th>\n      <th>month</th>\n      <th>Week_Number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2002</td>\n      <td>12</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2002</td>\n      <td>12</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2002</td>\n      <td>12</td>\n      <td>51</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2002</td>\n      <td>12</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.250000</td>\n      <td>0.250000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2003</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>957</th>\n      <td>0.138976</td>\n      <td>0.130617</td>\n      <td>0.133751</td>\n      <td>0.138976</td>\n      <td>0.133751</td>\n      <td>0.123302</td>\n      <td>0.131661</td>\n      <td>0.133751</td>\n      <td>0.104493</td>\n      <td>0.138976</td>\n      <td>...</td>\n      <td>0.143156</td>\n      <td>0.144201</td>\n      <td>0.123302</td>\n      <td>0.129572</td>\n      <td>0.147335</td>\n      <td>0.132706</td>\n      <td>0.138976</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>958</th>\n      <td>0.138831</td>\n      <td>0.131524</td>\n      <td>0.133612</td>\n      <td>0.138831</td>\n      <td>0.133612</td>\n      <td>0.123173</td>\n      <td>0.131524</td>\n      <td>0.133612</td>\n      <td>0.105428</td>\n      <td>0.139875</td>\n      <td>...</td>\n      <td>0.143006</td>\n      <td>0.144050</td>\n      <td>0.123173</td>\n      <td>0.129436</td>\n      <td>0.147182</td>\n      <td>0.132568</td>\n      <td>0.138831</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>959</th>\n      <td>0.139729</td>\n      <td>0.131387</td>\n      <td>0.133472</td>\n      <td>0.138686</td>\n      <td>0.133472</td>\n      <td>0.123045</td>\n      <td>0.131387</td>\n      <td>0.133472</td>\n      <td>0.105318</td>\n      <td>0.139729</td>\n      <td>...</td>\n      <td>0.142857</td>\n      <td>0.144943</td>\n      <td>0.124088</td>\n      <td>0.129301</td>\n      <td>0.147028</td>\n      <td>0.132430</td>\n      <td>0.138686</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>960</th>\n      <td>0.139583</td>\n      <td>0.132292</td>\n      <td>0.133333</td>\n      <td>0.138542</td>\n      <td>0.133333</td>\n      <td>0.122917</td>\n      <td>0.131250</td>\n      <td>0.133333</td>\n      <td>0.105208</td>\n      <td>0.139583</td>\n      <td>...</td>\n      <td>0.142708</td>\n      <td>0.144792</td>\n      <td>0.123958</td>\n      <td>0.129167</td>\n      <td>0.146875</td>\n      <td>0.132292</td>\n      <td>0.139583</td>\n      <td>2021</td>\n      <td>5</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>961</th>\n      <td>0.139438</td>\n      <td>0.132154</td>\n      <td>0.133195</td>\n      <td>0.138398</td>\n      <td>0.133195</td>\n      <td>0.122789</td>\n      <td>0.131113</td>\n      <td>0.133195</td>\n      <td>0.105099</td>\n      <td>0.139438</td>\n      <td>...</td>\n      <td>0.142560</td>\n      <td>0.144641</td>\n      <td>0.123829</td>\n      <td>0.130073</td>\n      <td>0.146722</td>\n      <td>0.132154</td>\n      <td>0.139438</td>\n      <td>2021</td>\n      <td>5</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n<p>962 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "state_pd = pd.concat([ratio_pd,data[[\"year\",\"month\",\"Week_Number\"]]],axis=1)\n",
    "state_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.140333  0.132017  0.133056  0.138254  0.133056  0.122661  0.130977   \n",
       "\n",
       "          8        9        10  ...        39        40        41        42  \\\n",
       "0  0.133056  0.10499  0.139293  ...  0.142412  0.144491  0.123701  0.129938   \n",
       "\n",
       "         43        44        45  year  month  Week_Number  \n",
       "0  0.147609  0.132017  0.139293  2021      5           19  \n",
       "\n",
       "[1 rows x 48 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>year</th>\n      <th>month</th>\n      <th>Week_Number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.140333</td>\n      <td>0.132017</td>\n      <td>0.133056</td>\n      <td>0.138254</td>\n      <td>0.133056</td>\n      <td>0.122661</td>\n      <td>0.130977</td>\n      <td>0.133056</td>\n      <td>0.10499</td>\n      <td>0.139293</td>\n      <td>...</td>\n      <td>0.142412</td>\n      <td>0.144491</td>\n      <td>0.123701</td>\n      <td>0.129938</td>\n      <td>0.147609</td>\n      <td>0.132017</td>\n      <td>0.139293</td>\n      <td>2021</td>\n      <td>5</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.date.today() \n",
    "\n",
    "test_table[\"year\"] = today.year\n",
    "test_table[\"month\"] = today.month\n",
    "test_table[\"Week_Number\"] = today.isocalendar()[1]\n",
    "\n",
    "test_table = test_table.loc[:,state_pd.columns.tolist()]\n",
    "test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     1    2    3    4    5    6    7    8    9    10  ...   36   37   38   39  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  1.0  0.0  0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "0   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  ...  0.0  1.0  0.0  0.0   \n",
       "0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "0   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "0   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     40   41   42   43   44   45  \n",
       "0   1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   1.0  0.0  1.0  0.0  0.0  0.0  \n",
       "0   1.0  1.0  1.0  0.0  0.0  0.0  \n",
       "..  ...  ...  ...  ...  ...  ...  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "0   1.0  1.0  0.0  0.0  0.0  0.0  \n",
       "0   0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "0   0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "0   0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[962 rows x 45 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>962 rows × 45 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "action_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "fac_cols = [\"year\",\"month\",\"Week_Number\"]\n"
   ]
  },
  {
   "source": [
    "# TODO\n",
    "\n",
    "* Category 개수에 따라서 나눠서 처리하기\n",
    "* 2개인 경우\n",
    "    * 하나의 컬럼으로 사용\n",
    "* 특정 n개 이하인 경우\n",
    "    * one hot으로 사용\n",
    "* 나머지\n",
    "    * embedding 으로 처리 \n",
    "    * min(50, (n+1)//2)\n",
    "\n",
    "* 현재\n",
    "    * min(50, (n+1)//2)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def collect_cat_info(df_input, fac_col ) :\n",
    "    categorical_columns = []\n",
    "    categorical_dims =  {}\n",
    "    categorical_positions =  {}\n",
    "    categorical_idxs =  []\n",
    "    encodding_scaler = {}\n",
    "    for idx , col in enumerate(df_input.columns.tolist()) :\n",
    "        if col in fac_col :\n",
    "            l_enc = LabelEncoder()\n",
    "            df_input[col] = df_input[col].fillna(\"VV_likely\")\n",
    "            df_input[col] = l_enc.fit_transform(df_input[col].values)\n",
    "            categorical_columns.append(col)\n",
    "            categorical_dims[col] = (len(l_enc.classes_), min(50,(len(l_enc.classes_)+1)//2))\n",
    "            categorical_positions[idx] = (len(l_enc.classes_), min(50,(len(l_enc.classes_)+1)//2))\n",
    "            categorical_idxs.append(idx)\n",
    "            encodding_scaler[col] = deepcopy(l_enc)\n",
    "    return categorical_columns , categorical_idxs, categorical_dims , categorical_positions , encodding_scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_column, emb_idx , emb_dims ,emb_dims_idxs , encodding_scaler= collect_cat_info(state_pd , fac_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "  from torch import nn \n",
    "  "
   ]
  },
  {
   "source": [
    "* Argument\n",
    "    * __init__\n",
    "        * input_length\n",
    "        * emb_dims \n",
    "        * output_len\n",
    "        * lin_layer_sizes\n",
    "        * emb_dropout_ratio\n",
    "    * forward\n",
    "        * num\n",
    "        * cat\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```\n",
    "\n",
    "output_len = action_pd.shape[1]\n",
    "input_len = state_pd.shape[1]\n",
    "######################################\n",
    "emb_length = sum([y for idx, (x, y) in emb_dims_idxs.items()])\n",
    "emb_layers = nn.ModuleDict([[str(idx) , nn.Embedding(x, y)] for idx, (x, y) in emb_dims_idxs.items()])\n",
    "no_of_embs = sum([y for idx, (x, y) in emb_dims_idxs.items()])\n",
    "no_of_fac = len([idx for idx, (x, y) in emb_dims_idxs.items()])\n",
    "no_of_cont = input_len - no_of_fac\n",
    "lin_layer_sizes = [50,25,10]\n",
    "emb_dropout_ratio = 0.7\n",
    "first_lin_layer = nn.Linear(no_of_embs +no_of_cont, lin_layer_sizes[0])\n",
    "emb_dropout_layer = nn.Dropout(emb_dropout_ratio)\n",
    "lin_layers =[first_lin_layer] +\\\n",
    "        [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1])\n",
    "        for i in range(len(lin_layer_sizes) - 1)]\n",
    "for lin_layer in lin_layers:\n",
    "    nn.init.kaiming_normal_(lin_layer.weight.data)\n",
    "bn_layers = [nn.BatchNorm1d(size) for size in lin_layer_sizes]\n",
    "output_layer = nn.Linear(lin_layer_sizes[-1], output_len)\n",
    "lin_acts = [nn.SELU() for _ in range(len(lin_layer_sizes))]\n",
    "inter_seq_layers = []\n",
    "for l , b , a in zip(lin_layers , bn_layers , lin_acts) :\n",
    "    inter_seq_layers.append(l)\n",
    "    inter_seq_layers.append(b)\n",
    "    inter_seq_layers.append(a)\n",
    "inter_layers = nn.Sequential(*inter_seq_layers)\n",
    "inter_layers\n",
    "fac_tensor = torch.LongTensor(state_pd[fac_cols].values)\n",
    "exclude_cols = fac_cols\n",
    "con_tensor = torch.FloatTensor(state_pd.filter(regex=\"^(?!({0})$).*$\".format('|'.join(exclude_cols))).values)\n",
    "################\n",
    "emb_tensor = torch.cat([emb_layer(fac_tensor[:,idx]) for idx, (col_idx , emb_layer) in enumerate(emb_layers.items())],axis=1)\n",
    "emb_tensor = emb_dropout_layer(emb_tensor)\n",
    "in_tensor = torch.cat([con_tensor,emb_tensor],axis=1)\n",
    "inter_tensor = inter_layers(in_tensor)\n",
    "output_tensor = output_layer(inter_tensor)\n",
    "\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularNN(nn.Module) :\n",
    "    def __init__(self, input_length,emb_dims_dict,output_len,lin_layer_sizes,emb_dropout_ratio) :\n",
    "        super(TabularNN,self).__init__()\n",
    "        self.emb_layers = nn.ModuleDict([[str(idx) , nn.Embedding(x, y)] for idx, (x, y) in emb_dims_dict.items()])\n",
    "        no_of_embs = sum([y for idx, (x, y) in emb_dims_dict.items()])\n",
    "        no_of_fac = len([idx for idx, (x, y) in emb_dims_dict.items()])\n",
    "        no_of_cont = input_len - no_of_fac\n",
    "        first_lin_layer = nn.Linear(no_of_embs +no_of_cont, lin_layer_sizes[0])\n",
    "        self.emb_dropout_layer = nn.Dropout(emb_dropout_ratio)\n",
    "        lin_layers =[first_lin_layer] + \\\n",
    "            [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1]) for i in range(len(lin_layer_sizes) - 1)]\n",
    "        for lin_layer in lin_layers:\n",
    "            nn.init.kaiming_normal_(lin_layer.weight.data)\n",
    "        lin_acts = [nn.SELU() for _ in range(len(lin_layer_sizes))]\n",
    "        bn_layers = [nn.BatchNorm1d(size) for size in lin_layer_sizes]\n",
    "        inter_seq_layers = []\n",
    "        for l , b , a in zip(lin_layers , bn_layers , lin_acts) :\n",
    "            inter_seq_layers.append(l)\n",
    "            inter_seq_layers.append(b)\n",
    "            inter_seq_layers.append(a)\n",
    "        self.inter_layers = nn.Sequential(*inter_seq_layers)\n",
    "        self.output_layer = nn.Linear(lin_layer_sizes[-1], output_len)\n",
    "\n",
    "    def forward(self, con_tensor , fac_tensor) :\n",
    "        emb_tensor = torch.cat([emb_layer(fac_tensor[:,idx]) for idx, (col_idx , emb_layer) in enumerate(self.emb_layers.items())],axis=1)\n",
    "        emb_tensor = self.emb_dropout_layer(emb_tensor)\n",
    "        in_tensor = torch.cat([con_tensor,emb_tensor],axis=1)\n",
    "        inter_tensor = self.inter_layers(in_tensor)\n",
    "        output_tensor = self.output_layer(inter_tensor)\n",
    "        return output_tensor\n",
    "\n",
    "    def check_array(self, x) :\n",
    "        print(x)\n",
    "        if x.ndim == 1 :\n",
    "            return x.unsqueeze(dim=0)\n",
    "        elif x.ndim == 2 :\n",
    "            return x\n",
    "        else :\n",
    "            raise Exception(f\"Check dimension : {x.ndim}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_len = action_pd.shape[1]\n",
    "input_len = state_pd.shape[1]\n",
    "tabular_nn = TabularNN(input_len , emb_dims_idxs , output_len , [100,50,20],0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_tensor = torch.LongTensor(state_pd[fac_cols].values)\n",
    "exclude_cols = fac_cols\n",
    "con_tensor = torch.FloatTensor(state_pd.filter(regex=\"^(?!({0})$).*$\".format('|'.join(exclude_cols))).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.1394,  0.4289, -0.7825,  ..., -0.6321, -0.5225,  0.2592],\n",
       "        [-0.0764,  0.6583, -0.8885,  ..., -0.0278,  0.3486, -0.2071],\n",
       "        [ 0.8856, -0.1202, -0.9562,  ...,  0.9127, -0.4619, -0.2076],\n",
       "        ...,\n",
       "        [-0.0851,  0.1615,  0.7453,  ..., -0.2432,  1.1484,  0.3750],\n",
       "        [-0.5781,  0.0517,  0.7594,  ..., -0.6000,  1.0679,  0.7406],\n",
       "        [-0.0296, -0.0877,  0.5714,  ...,  0.5111,  1.1742,  0.7140]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "tabular_nn(con_tensor,fac_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X,Y,fac_cols) :\n",
    "        self.num_cols = []\n",
    "        for col in X.columns.tolist() :\n",
    "            if col not in fac_cols :\n",
    "                self.num_cols.append(col)\n",
    "        self.fac_cols = fac_cols\n",
    "        self.n = X.shape[0]\n",
    "        if self.num_cols :\n",
    "            self.cont_x = X[self.num_cols].astype(np.float32).values     \n",
    "        else :\n",
    "            self.cont_X = np.zeros((self.n, 1))\n",
    "        if self.fac_cols :\n",
    "            self.fac_x = X[fac_cols].astype(np.int32).values\n",
    "        else :\n",
    "            self.fac_x = np.zeros((self.n, 1))\n",
    "        if Y is None :\n",
    "            self.y = np.zeros((self.n, 1))\n",
    "        else : \n",
    "            self.y = Y.values.astype(np.int32)\n",
    "\n",
    "    def __len__(self) :\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self,idx) :\n",
    "        return [self.cont_x[idx], self.fac_x[idx] , self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = TabularDataset(state_pd , action_pd, fac_cols)\n",
    "batchsize= 32\n",
    "dataloader = DataLoader(dataset, batchsize, shuffle=True, num_workers=5)\n",
    "\n",
    "optimizer = torch.optim.Adam(tabular_nn.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cont_batch, x_fac_batch , y_batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://stackoverflow.com/questions/38543506/change-logging-print-function-to-tqdm-write-so-logging-doesnt-interfere-wit\n",
    "\"\"\"\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TqdmLoggingHandler(logging.StreamHandler):\n",
    "    \"\"\"Avoid tqdm progress bar interruption by logger's output to console\"\"\"\n",
    "    # see logging.StreamHandler.eval method:\n",
    "    # https://github.com/python/cpython/blob/d2e2534751fd675c4d5d3adc208bf4fc984da7bf/Lib/logging/__init__.py#L1082-L1091\n",
    "    # and tqdm.write method:\n",
    "    # https://github.com/tqdm/tqdm/blob/f86104a1f30c38e6f80bfd8fb16d5fcde1e7749f/tqdm/std.py#L614-L620\n",
    "\n",
    "    def emit(self, record):\n",
    "        try:\n",
    "            msg = self.format(record)\n",
    "            tqdm.write(msg, end=self.terminator)\n",
    "        except RecursionError:\n",
    "            raise\n",
    "        except Exception:\n",
    "            self.handleError(record)\n",
    "import time\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "log.handlers = []\n",
    "log.setLevel(logging.INFO)\n",
    "log.addHandler(TqdmLoggingHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"./model.pt\") :\n",
    "    checkpoint = torch.load(\"./model.pt\")\n",
    "    tabular_nn.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # epoch = checkpoint['epoch']\n",
    "    loss_store = checkpoint['loss_history']\n",
    "else :\n",
    "    loss_store = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ee591422c3cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtabular_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "tabular_nn.train()\n",
    "pbar = tqdm(range(10000))\n",
    "for epoch in pbar :\n",
    "    loss_ = 0\n",
    "    for x_cont_batch, x_fac_batch , y_batch in dataloader :\n",
    "        logit = tabular_nn(x_cont_batch,x_fac_batch)\n",
    "        # prob = nn.Sigmoid()(logit)\n",
    "        loss = criterion(logit , y_batch.float())\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        loss_ += loss.detach().numpy()\n",
    "    _loss_ = loss_/len(dataloader)\n",
    "    loss_store.append(_loss_)\n",
    "    if len(loss_store) > 1 :\n",
    "        if  _loss_ < np.min(loss_store[:-1]) : \n",
    "            torch.save({'epoch': epoch,\n",
    "            'model_state_dict': tabular_nn.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss_history' : loss_store,\n",
    "            },\"./model.pt\")\n",
    "    if epoch % 500 == 0 :\n",
    "        log.info(f\"loss : {str(loss_/len(dataloader))}, minimum : {np.min(loss_store)}\")\n",
    "    pbar.set_postfix({'loss': _loss_, 'best' : np.min(loss_store)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 384.828125 248.518125\" width=\"384.828125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-05-15T05:04:52.844652</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 384.828125 248.518125 \nL 384.828125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 42.828125 224.64 \nL 377.628125 224.64 \nL 377.628125 7.2 \nL 42.828125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0764e954bf\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"58.046307\" xlink:href=\"#m0764e954bf\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(54.865057 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.979968\" xlink:href=\"#m0764e954bf\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <g transform=\"translate(109.436218 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"179.913629\" xlink:href=\"#m0764e954bf\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <g transform=\"translate(170.369879 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"240.84729\" xlink:href=\"#m0764e954bf\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <g transform=\"translate(231.30354 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"301.780951\" xlink:href=\"#m0764e954bf\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <g transform=\"translate(292.237201 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"362.714611\" xlink:href=\"#m0764e954bf\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1000 -->\n      <g transform=\"translate(349.989611 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mc1b47b1892\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#mc1b47b1892\" y=\"206.403623\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.315 -->\n      <g transform=\"translate(7.2 210.202842)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#mc1b47b1892\" y=\"165.245589\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.320 -->\n      <g transform=\"translate(7.2 169.044808)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#mc1b47b1892\" y=\"124.087556\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.325 -->\n      <g transform=\"translate(7.2 127.886775)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#mc1b47b1892\" y=\"82.929522\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.330 -->\n      <g transform=\"translate(7.2 86.728741)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.828125\" xlink:href=\"#mc1b47b1892\" y=\"41.771489\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.335 -->\n      <g transform=\"translate(7.2 45.570707)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pa11b96d53d)\" d=\"M 58.046307 52.200902 \nL 58.350975 24.079558 \nL 58.655643 30.042401 \nL 58.960312 62.334186 \nL 59.26498 43.720946 \nL 59.569648 62.037625 \nL 59.874317 61.53869 \nL 60.178985 33.104245 \nL 60.483653 55.082529 \nL 60.788322 51.142991 \nL 61.09299 55.410175 \nL 61.397658 35.057135 \nL 61.702326 24.53049 \nL 62.006995 77.20769 \nL 62.311663 29.377653 \nL 62.616331 17.083636 \nL 62.921 60.782333 \nL 63.225668 66.63722 \nL 63.530336 68.615631 \nL 63.835005 62.637182 \nL 64.139673 39.491122 \nL 64.74901 52.248945 \nL 65.053678 52.400253 \nL 65.358346 56.732693 \nL 65.663014 58.977246 \nL 65.967683 63.923605 \nL 66.272351 81.184201 \nL 66.577019 80.633787 \nL 66.881688 50.992182 \nL 67.491024 68.959578 \nL 67.795693 63.230716 \nL 68.100361 54.571913 \nL 68.405029 27.481377 \nL 68.709697 57.481808 \nL 69.014366 36.081595 \nL 69.623702 58.236234 \nL 69.928371 64.038819 \nL 70.233039 58.644218 \nL 70.537707 66.582822 \nL 70.842376 47.594138 \nL 71.147044 46.045956 \nL 71.451712 46.202629 \nL 71.756381 52.832659 \nL 72.061049 74.476531 \nL 72.365717 51.972698 \nL 72.670385 66.272641 \nL 72.975054 61.448269 \nL 73.279722 66.018045 \nL 73.58439 37.428273 \nL 73.889059 57.901909 \nL 74.193727 47.736321 \nL 74.498395 74.720697 \nL 75.107732 35.032492 \nL 75.4124 64.199963 \nL 75.717068 68.340776 \nL 76.021737 78.47209 \nL 76.326405 73.926157 \nL 76.631073 97.364949 \nL 76.935742 54.59563 \nL 77.24041 45.677009 \nL 77.849747 100.265972 \nL 78.154415 46.609174 \nL 78.459083 58.808109 \nL 78.763752 53.458773 \nL 79.06842 60.343486 \nL 79.373088 63.961171 \nL 79.677756 33.965005 \nL 79.982425 68.552559 \nL 80.287093 59.772956 \nL 80.89643 90.406292 \nL 81.201098 64.178921 \nL 81.505766 65.265266 \nL 81.810435 65.404941 \nL 82.115103 80.608757 \nL 82.419771 30.756919 \nL 82.724439 75.080005 \nL 83.029108 40.745369 \nL 83.333776 46.351571 \nL 83.638444 17.614733 \nL 83.943113 56.615311 \nL 84.247781 35.311525 \nL 84.552449 49.450197 \nL 84.857118 34.621476 \nL 85.161786 74.112688 \nL 85.466454 43.784326 \nL 86.075791 37.370385 \nL 86.380459 44.332698 \nL 86.685127 29.254937 \nL 86.989796 74.235855 \nL 87.294464 82.369885 \nL 87.599132 72.456732 \nL 87.903801 38.943502 \nL 88.208469 62.691635 \nL 88.513137 34.892097 \nL 88.817806 72.192601 \nL 89.122474 50.876287 \nL 89.427142 45.647215 \nL 89.731811 77.501054 \nL 90.036479 42.162968 \nL 90.341147 53.968234 \nL 90.645815 60.092688 \nL 90.950484 48.128114 \nL 91.255152 58.807072 \nL 91.55982 41.652099 \nL 91.864489 35.383609 \nL 92.169157 67.8357 \nL 92.473825 60.943161 \nL 92.778494 76.359718 \nL 93.083162 45.486894 \nL 93.38783 59.17734 \nL 93.692498 37.394529 \nL 93.997167 71.290397 \nL 94.301835 80.399071 \nL 94.606503 64.202195 \nL 94.911172 88.909945 \nL 95.21584 78.343075 \nL 95.520508 87.885334 \nL 95.825177 83.673655 \nL 96.434513 37.657268 \nL 96.739182 72.649784 \nL 97.04385 63.168586 \nL 97.348518 97.4243 \nL 97.653186 36.738834 \nL 97.957855 35.263663 \nL 98.262523 66.671525 \nL 98.567191 51.185463 \nL 98.87186 65.508149 \nL 99.176528 89.658308 \nL 99.481196 81.438504 \nL 99.785865 88.956833 \nL 100.090533 46.739835 \nL 100.395201 88.915603 \nL 100.699869 73.096102 \nL 101.004538 64.739488 \nL 101.309206 71.468239 \nL 101.613874 55.993011 \nL 101.918543 63.922078 \nL 102.527879 96.686992 \nL 102.832548 56.663948 \nL 103.137216 57.356552 \nL 103.441884 63.917385 \nL 103.746553 68.013399 \nL 104.051221 83.97278 \nL 104.355889 87.637235 \nL 104.660557 55.387012 \nL 104.965226 90.072521 \nL 105.269894 71.972611 \nL 105.574562 86.527529 \nL 105.879231 57.403986 \nL 106.183899 92.197942 \nL 106.488567 88.349188 \nL 106.793236 36.147681 \nL 107.097904 72.575618 \nL 107.402572 85.556407 \nL 107.70724 59.553212 \nL 108.011909 77.093568 \nL 108.316577 72.950081 \nL 108.621245 86.40737 \nL 108.925914 80.605932 \nL 109.230582 82.19873 \nL 109.53525 63.993237 \nL 109.839919 74.656636 \nL 110.144587 102.033312 \nL 110.449255 89.12536 \nL 110.753924 90.38354 \nL 111.058592 96.538913 \nL 111.667928 51.209481 \nL 111.972597 98.193208 \nL 112.277265 94.714706 \nL 112.581933 75.78611 \nL 112.886602 88.957181 \nL 113.19127 74.157092 \nL 113.495938 69.924782 \nL 113.800607 46.597794 \nL 114.105275 67.960987 \nL 114.409943 70.788494 \nL 114.714611 101.305461 \nL 115.01928 96.02548 \nL 115.323948 108.775604 \nL 115.628616 88.449976 \nL 115.933285 98.066559 \nL 116.237953 77.035878 \nL 116.542621 76.066749 \nL 116.84729 60.782531 \nL 117.151958 56.335874 \nL 117.456626 78.929938 \nL 117.761295 64.148952 \nL 118.065963 63.41401 \nL 118.370631 80.381392 \nL 118.979968 82.458287 \nL 119.284636 98.443016 \nL 119.589304 107.13841 \nL 119.893973 93.491757 \nL 120.503309 46.625317 \nL 120.807978 42.41758 \nL 121.417314 122.635449 \nL 121.721982 66.513878 \nL 122.026651 88.91148 \nL 122.331319 90.028695 \nL 122.635987 67.800975 \nL 122.940656 75.260894 \nL 123.245324 97.275588 \nL 123.549992 86.272214 \nL 123.854661 88.493413 \nL 124.463997 54.953855 \nL 124.768666 68.239704 \nL 125.378002 61.184034 \nL 125.68267 98.212469 \nL 125.987339 83.785284 \nL 126.292007 88.72995 \nL 126.596675 108.651875 \nL 126.901344 76.150918 \nL 127.206012 83.559502 \nL 127.51068 72.355138 \nL 127.815349 80.633669 \nL 128.120017 96.707449 \nL 128.424685 75.65351 \nL 128.729354 80.885606 \nL 129.034022 74.721077 \nL 129.33869 102.893867 \nL 129.948027 67.597319 \nL 130.252695 101.323773 \nL 130.557363 92.095604 \nL 130.862032 122.245713 \nL 131.1667 64.891626 \nL 131.471368 53.044735 \nL 131.776037 63.917694 \nL 132.080705 93.604391 \nL 132.385373 84.374529 \nL 132.690041 48.06134 \nL 132.99471 80.958656 \nL 133.299378 73.473358 \nL 133.908715 99.221593 \nL 134.213383 56.390961 \nL 134.518051 66.008106 \nL 134.82272 102.039414 \nL 135.432056 64.64932 \nL 135.736725 104.556826 \nL 136.041393 128.593267 \nL 136.650729 96.345664 \nL 136.955398 71.551688 \nL 137.260066 103.754358 \nL 137.564734 70.288957 \nL 137.869403 95.148457 \nL 138.174071 69.005256 \nL 138.478739 92.077957 \nL 138.783408 94.588216 \nL 139.088076 80.329756 \nL 139.697412 73.007066 \nL 140.002081 99.964267 \nL 140.306749 91.179528 \nL 140.611417 125.348936 \nL 140.916086 82.232806 \nL 141.220754 95.529631 \nL 141.525422 102.983472 \nL 141.830091 58.89902 \nL 142.134759 72.707221 \nL 142.439427 104.362833 \nL 143.353432 77.077638 \nL 143.6581 86.023727 \nL 143.962769 80.911515 \nL 144.267437 99.355863 \nL 144.572105 71.970063 \nL 144.876774 78.823049 \nL 145.181442 80.181827 \nL 145.48611 123.415427 \nL 146.095447 97.58243 \nL 146.400115 107.96132 \nL 146.704783 73.479064 \nL 147.009452 63.72154 \nL 147.31412 71.406584 \nL 147.923457 78.670294 \nL 148.228125 107.646755 \nL 148.532793 93.693854 \nL 148.837462 128.461672 \nL 149.14213 97.557264 \nL 149.446798 86.691681 \nL 149.751467 80.655273 \nL 150.056135 116.399246 \nL 150.360803 77.657688 \nL 150.665471 108.90192 \nL 150.97014 99.097334 \nL 151.274808 97.403511 \nL 151.579476 73.576591 \nL 151.884145 105.149055 \nL 152.188813 96.876182 \nL 152.493481 114.779645 \nL 152.79815 94.671751 \nL 153.102818 95.987028 \nL 153.407486 85.130767 \nL 154.016823 102.847612 \nL 154.321491 79.3118 \nL 154.626159 109.079517 \nL 154.930828 78.880091 \nL 155.235496 78.195993 \nL 155.540164 112.285625 \nL 155.844833 97.870571 \nL 156.149501 103.991314 \nL 156.454169 83.970897 \nL 156.758838 77.118401 \nL 157.063506 101.967052 \nL 157.368174 76.730176 \nL 157.672842 119.26746 \nL 157.977511 134.214172 \nL 158.586847 109.192333 \nL 158.891516 105.838454 \nL 159.196184 105.42641 \nL 159.500852 117.300627 \nL 159.805521 118.287514 \nL 160.110189 127.181824 \nL 160.414857 88.407867 \nL 160.719525 82.774063 \nL 161.024194 104.833754 \nL 161.328862 59.654474 \nL 161.63353 58.532748 \nL 161.938199 70.870779 \nL 162.242867 99.294105 \nL 163.156872 113.495762 \nL 163.766209 82.149357 \nL 164.070877 110.328707 \nL 164.375545 96.034873 \nL 164.680213 89.655823 \nL 164.984882 102.520987 \nL 165.28955 127.625681 \nL 165.594218 109.059211 \nL 165.898887 97.427102 \nL 166.203555 75.287926 \nL 166.508223 125.810733 \nL 166.812892 107.550051 \nL 167.11756 120.86105 \nL 167.726896 101.28225 \nL 168.031565 74.393439 \nL 168.336233 100.998145 \nL 168.640901 113.340877 \nL 168.94557 96.58478 \nL 169.250238 112.609274 \nL 169.554906 122.020967 \nL 169.859575 90.124909 \nL 170.164243 97.353015 \nL 170.468911 107.905363 \nL 170.77358 91.128699 \nL 171.078248 124.325631 \nL 171.687584 83.408131 \nL 171.992253 111.272536 \nL 172.296921 81.755047 \nL 172.601589 125.466951 \nL 172.906258 104.691531 \nL 173.210926 74.453273 \nL 173.515594 83.53307 \nL 173.820263 122.702318 \nL 174.124931 88.338893 \nL 174.429599 101.654798 \nL 174.734268 106.854495 \nL 175.038936 101.954034 \nL 175.343604 110.457778 \nL 175.648272 132.505535 \nL 175.952941 127.849628 \nL 176.257609 105.986067 \nL 176.562277 113.283361 \nL 176.866946 93.003909 \nL 177.171614 122.565952 \nL 177.476282 111.232011 \nL 177.780951 124.547306 \nL 178.085619 99.412144 \nL 178.390287 123.003533 \nL 178.694955 109.598664 \nL 178.999624 72.257215 \nL 179.304292 108.314733 \nL 179.60896 102.749024 \nL 179.913629 90.611428 \nL 180.218297 98.158886 \nL 180.522965 73.600047 \nL 180.827634 124.89108 \nL 181.132302 145.785062 \nL 181.43697 129.290232 \nL 181.741639 133.401432 \nL 182.046307 106.823062 \nL 182.350975 115.46713 \nL 182.655643 70.522178 \nL 182.960312 120.392637 \nL 183.26498 93.938447 \nL 183.569648 111.053908 \nL 183.874317 86.873084 \nL 184.178985 88.404132 \nL 184.483653 130.241602 \nL 184.788322 84.101724 \nL 185.09299 125.19068 \nL 185.397658 97.225638 \nL 185.702326 108.248678 \nL 186.006995 97.906799 \nL 186.311663 113.500304 \nL 186.616331 94.811078 \nL 186.921 118.899819 \nL 187.530336 90.88083 \nL 187.835005 106.759975 \nL 188.139673 135.070335 \nL 188.444341 93.702923 \nL 189.053678 153.508661 \nL 189.358346 115.621808 \nL 189.663014 134.186871 \nL 189.967683 106.479106 \nL 190.272351 119.882045 \nL 190.577019 123.352831 \nL 190.881688 73.698974 \nL 191.186356 121.186068 \nL 191.491024 106.939613 \nL 191.795693 121.861152 \nL 192.100361 104.403437 \nL 192.405029 106.830928 \nL 192.709697 114.401661 \nL 193.014366 112.031179 \nL 193.319034 83.152387 \nL 193.623702 92.677513 \nL 193.928371 141.561607 \nL 194.233039 118.863741 \nL 194.842376 108.137611 \nL 195.147044 87.879478 \nL 195.451712 100.930286 \nL 195.756381 101.323907 \nL 196.061049 112.872448 \nL 196.365717 160.013094 \nL 196.670385 99.256429 \nL 196.975054 136.451294 \nL 197.279722 126.497086 \nL 197.58439 77.990572 \nL 197.889059 126.234054 \nL 198.193727 130.198774 \nL 198.498395 118.06007 \nL 198.803064 142.608416 \nL 199.107732 102.327278 \nL 199.4124 104.169061 \nL 199.717068 128.184151 \nL 200.021737 133.450844 \nL 200.326405 83.529659 \nL 200.935742 124.87849 \nL 201.24041 87.52123 \nL 201.545078 105.864063 \nL 201.849747 110.795909 \nL 202.154415 88.540056 \nL 202.459083 127.542882 \nL 203.06842 105.734953 \nL 203.373088 122.434974 \nL 203.677756 86.657296 \nL 203.982425 132.074641 \nL 204.287093 140.475563 \nL 204.591761 130.003293 \nL 204.89643 131.78422 \nL 205.201098 113.764317 \nL 205.505766 114.260451 \nL 205.810435 124.704383 \nL 206.115103 147.516798 \nL 206.419771 120.225075 \nL 206.724439 119.341808 \nL 207.029108 146.614563 \nL 207.333776 120.868734 \nL 207.638444 149.847166 \nL 207.943113 141.006019 \nL 208.247781 124.1003 \nL 208.552449 100.405053 \nL 208.857118 113.785937 \nL 209.161786 148.052896 \nL 209.466454 112.696664 \nL 209.771123 138.465443 \nL 210.075791 102.681751 \nL 210.685127 139.923536 \nL 210.989796 129.942754 \nL 211.294464 105.876804 \nL 211.599132 130.384245 \nL 211.903801 130.360567 \nL 212.208469 146.189857 \nL 212.817806 112.40785 \nL 213.122474 119.955625 \nL 213.427142 119.971674 \nL 213.731811 133.027563 \nL 214.036479 108.639506 \nL 214.341147 145.727577 \nL 214.645815 152.761381 \nL 214.950484 115.721733 \nL 215.255152 110.805492 \nL 215.55982 127.477547 \nL 215.864489 121.636858 \nL 216.169157 109.237519 \nL 216.473825 124.148905 \nL 216.778494 109.04825 \nL 217.083162 164.011106 \nL 217.38783 124.153503 \nL 217.692498 129.170555 \nL 217.997167 153.827277 \nL 218.301835 144.900814 \nL 218.606503 147.154 \nL 218.911172 110.484929 \nL 219.21584 96.28025 \nL 219.520508 126.942684 \nL 219.825177 108.372003 \nL 220.129845 124.555093 \nL 220.434513 126.117938 \nL 220.739182 134.714176 \nL 221.04385 114.00246 \nL 221.348518 145.164273 \nL 221.653186 148.313 \nL 221.957855 164.853261 \nL 222.262523 145.127704 \nL 222.567191 139.250913 \nL 222.87186 108.292654 \nL 223.176528 146.997968 \nL 223.481196 134.458599 \nL 223.785865 102.03552 \nL 224.090533 130.355495 \nL 224.395201 145.359738 \nL 224.699869 103.753107 \nL 225.004538 117.809842 \nL 225.309206 137.787107 \nL 225.613874 116.716985 \nL 225.918543 117.054934 \nL 226.223211 161.484751 \nL 226.527879 139.439454 \nL 226.832548 138.449434 \nL 227.137216 141.534314 \nL 227.441884 121.388878 \nL 228.051221 155.953087 \nL 228.660557 136.325342 \nL 229.269894 100.344103 \nL 229.574562 133.96821 \nL 229.879231 113.485094 \nL 230.183899 105.82383 \nL 230.488567 152.800039 \nL 231.097904 103.667926 \nL 231.402572 139.572648 \nL 231.70724 132.643968 \nL 232.011909 131.047387 \nL 232.316577 149.48489 \nL 232.621245 138.067793 \nL 232.925914 133.359268 \nL 233.230582 102.972069 \nL 233.53525 130.695612 \nL 233.839919 117.069163 \nL 234.144587 165.488666 \nL 234.753924 140.455249 \nL 235.058592 116.451049 \nL 235.36326 134.281374 \nL 235.667928 145.059157 \nL 235.972597 123.612348 \nL 236.277265 120.163254 \nL 236.886602 143.116325 \nL 237.19127 144.615023 \nL 237.495938 126.136076 \nL 237.800607 132.617877 \nL 238.105275 97.816988 \nL 238.409943 147.626995 \nL 238.714611 127.142502 \nL 239.01928 136.819458 \nL 239.323948 138.874156 \nL 239.628616 120.791553 \nL 239.933285 144.106203 \nL 240.237953 157.856184 \nL 240.542621 106.898985 \nL 240.84729 149.565039 \nL 241.151958 118.079909 \nL 241.456626 146.731391 \nL 241.761295 121.943398 \nL 242.065963 149.865217 \nL 242.675299 135.746155 \nL 242.979968 103.730118 \nL 243.284636 132.799612 \nL 243.589304 118.718282 \nL 243.893973 122.571626 \nL 244.198641 161.818451 \nL 244.807978 112.839916 \nL 245.417314 158.482726 \nL 245.721982 140.471488 \nL 246.026651 133.218375 \nL 246.331319 157.580602 \nL 246.635987 170.938979 \nL 246.940656 122.184818 \nL 247.245324 141.368682 \nL 247.549992 142.779595 \nL 247.854661 146.898716 \nL 248.159329 118.498759 \nL 248.463997 133.763241 \nL 248.768666 124.456237 \nL 249.073334 169.753928 \nL 249.378002 143.61678 \nL 249.68267 101.242769 \nL 249.987339 124.040624 \nL 250.292007 120.202402 \nL 250.901344 179.38379 \nL 251.206012 174.147002 \nL 251.51068 118.134093 \nL 251.815349 118.346644 \nL 252.120017 162.148629 \nL 252.424685 154.647544 \nL 252.729354 172.277609 \nL 253.034022 120.856579 \nL 253.33869 152.686495 \nL 253.643358 107.040472 \nL 253.948027 149.575651 \nL 254.252695 124.056918 \nL 254.557363 152.313536 \nL 254.862032 113.039599 \nL 255.1667 181.09579 \nL 255.471368 156.572546 \nL 256.080705 143.40578 \nL 256.690041 118.340384 \nL 256.99471 161.903632 \nL 257.299378 134.287199 \nL 257.604046 137.875826 \nL 257.908715 114.696371 \nL 258.213383 145.154547 \nL 258.518051 134.532615 \nL 258.82272 132.421272 \nL 259.127388 186.494617 \nL 259.432056 102.466438 \nL 259.736725 160.960706 \nL 260.041393 134.32095 \nL 260.346061 141.41026 \nL 260.650729 144.68194 \nL 260.955398 153.006473 \nL 261.564734 108.628815 \nL 261.869403 123.885581 \nL 262.174071 133.521821 \nL 262.478739 176.070936 \nL 262.783408 183.119024 \nL 263.088076 136.138185 \nL 263.392744 157.748575 \nL 263.697412 118.337108 \nL 264.002081 143.410948 \nL 264.306749 150.854391 \nL 264.611417 183.102136 \nL 264.916086 121.474772 \nL 265.220754 157.520166 \nL 265.525422 158.551828 \nL 265.830091 164.408922 \nL 266.439427 143.729944 \nL 266.744096 170.199518 \nL 267.048764 133.432097 \nL 267.353432 141.353536 \nL 267.6581 116.128285 \nL 267.962769 161.945788 \nL 268.572105 128.587498 \nL 268.876774 126.219003 \nL 269.181442 140.44512 \nL 269.48611 166.778715 \nL 269.790779 158.457632 \nL 270.095447 96.436749 \nL 270.704783 134.913598 \nL 271.009452 136.343567 \nL 271.31412 158.269439 \nL 271.618788 134.691385 \nL 271.923457 154.422197 \nL 272.228125 142.364227 \nL 272.532793 137.266828 \nL 272.837462 156.049355 \nL 273.14213 165.195516 \nL 273.751467 143.422897 \nL 274.056135 160.891343 \nL 274.360803 148.938077 \nL 274.665471 158.297699 \nL 274.97014 141.377981 \nL 275.274808 165.418275 \nL 275.579476 158.746818 \nL 275.884145 136.928317 \nL 276.493481 170.424628 \nL 276.79815 127.087526 \nL 277.407486 143.466913 \nL 277.712154 164.247168 \nL 278.016823 121.21618 \nL 278.626159 180.635212 \nL 278.930828 128.301659 \nL 279.540164 156.995242 \nL 279.844833 130.55889 \nL 280.149501 122.845459 \nL 280.454169 145.70955 \nL 280.758838 150.790947 \nL 281.063506 112.751276 \nL 281.672842 166.991922 \nL 281.977511 157.719153 \nL 282.282179 141.205932 \nL 282.891516 182.502493 \nL 283.196184 170.00592 \nL 283.500852 123.045736 \nL 283.805521 145.489038 \nL 284.110189 159.379461 \nL 284.414857 161.493171 \nL 284.719525 152.108685 \nL 285.024194 135.393834 \nL 285.328862 140.982935 \nL 285.63353 188.941172 \nL 285.938199 160.76251 \nL 286.242867 168.574235 \nL 286.547535 160.577134 \nL 286.852204 129.738576 \nL 287.156872 185.349047 \nL 287.766209 165.628974 \nL 288.070877 118.463195 \nL 288.375545 131.923357 \nL 288.680213 134.401408 \nL 288.984882 130.311891 \nL 289.28955 179.448951 \nL 289.594218 142.943714 \nL 289.898887 125.084243 \nL 290.203555 157.791783 \nL 290.508223 174.61604 \nL 290.812892 152.81961 \nL 291.11756 153.317746 \nL 291.422228 174.510679 \nL 291.726896 141.063463 \nL 292.031565 158.171145 \nL 292.336233 120.390002 \nL 292.640901 147.89062 \nL 292.94557 147.544005 \nL 293.250238 155.90009 \nL 293.554906 170.072038 \nL 293.859575 146.128543 \nL 294.164243 190.481898 \nL 294.77358 143.277066 \nL 295.382916 179.476181 \nL 295.687584 151.817022 \nL 295.992253 139.247471 \nL 296.601589 172.540213 \nL 296.906258 132.675859 \nL 297.210926 176.203773 \nL 297.515594 146.257099 \nL 297.820263 142.985348 \nL 298.124931 163.446187 \nL 298.429599 138.928411 \nL 298.734268 156.520221 \nL 299.038936 146.838454 \nL 299.343604 190.048677 \nL 300.257609 148.07192 \nL 300.562277 148.616454 \nL 300.866946 167.58074 \nL 301.171614 160.230084 \nL 301.476282 165.933449 \nL 301.780951 182.637712 \nL 302.085619 171.2297 \nL 302.390287 165.652478 \nL 302.694955 165.947084 \nL 302.999624 160.703063 \nL 303.304292 142.758924 \nL 303.60896 149.417498 \nL 303.913629 187.403666 \nL 304.522965 155.591499 \nL 304.827634 153.593605 \nL 305.132302 181.411162 \nL 305.43697 131.621201 \nL 305.741639 172.105045 \nL 306.046307 162.985728 \nL 306.350975 139.644163 \nL 306.655643 155.33582 \nL 306.960312 155.432983 \nL 307.26498 155.090372 \nL 307.569648 159.055551 \nL 307.874317 182.205583 \nL 308.178985 139.004927 \nL 308.483653 139.311444 \nL 308.788322 167.0445 \nL 309.09299 153.399177 \nL 309.397658 146.492322 \nL 309.702326 187.372748 \nL 310.006995 141.533055 \nL 310.311663 158.184281 \nL 310.616331 159.965011 \nL 310.921 163.763086 \nL 311.225668 156.884966 \nL 311.530336 147.042957 \nL 311.835005 131.160923 \nL 312.139673 194.078368 \nL 312.444341 153.480132 \nL 312.74901 176.390375 \nL 313.053678 146.299611 \nL 313.358346 174.168266 \nL 313.663014 178.014472 \nL 313.967683 178.542774 \nL 314.577019 166.101906 \nL 314.881688 153.622988 \nL 315.491024 150.733424 \nL 315.795693 185.073781 \nL 316.405029 161.74438 \nL 316.709697 170.865778 \nL 317.014366 168.098565 \nL 317.319034 158.474686 \nL 317.623702 142.091058 \nL 317.928371 169.456472 \nL 318.233039 167.921934 \nL 318.537707 168.193979 \nL 318.842376 193.862169 \nL 319.147044 150.928857 \nL 319.451712 148.275188 \nL 319.756381 131.386492 \nL 320.061049 132.881177 \nL 320.365717 173.664305 \nL 320.670385 162.940533 \nL 320.975054 175.907702 \nL 321.58439 170.299562 \nL 321.889059 137.569 \nL 322.193727 181.337637 \nL 322.498395 170.948277 \nL 322.803064 198.750925 \nL 323.107732 166.986921 \nL 323.717068 154.657436 \nL 324.021737 160.939964 \nL 324.326405 131.318657 \nL 324.631073 173.021841 \nL 324.935742 147.315849 \nL 325.24041 178.193999 \nL 325.545078 163.307636 \nL 325.849747 134.918323 \nL 326.154415 166.139661 \nL 326.459083 144.245253 \nL 326.763752 180.965667 \nL 327.06842 176.342815 \nL 327.373088 195.002539 \nL 327.677756 160.396618 \nL 327.982425 175.52004 \nL 328.287093 175.091171 \nL 328.591761 177.029658 \nL 328.89643 158.740297 \nL 329.201098 153.696632 \nL 329.505766 167.661601 \nL 329.810435 167.644088 \nL 330.115103 158.840349 \nL 330.724439 166.706962 \nL 331.029108 155.363438 \nL 331.333776 179.48233 \nL 331.638444 191.397951 \nL 331.943113 134.921892 \nL 332.247781 136.219292 \nL 332.552449 166.514045 \nL 332.857118 154.348814 \nL 333.161786 178.840562 \nL 333.466454 164.5468 \nL 333.771123 142.504352 \nL 334.075791 156.469258 \nL 334.380459 188.454613 \nL 334.989796 142.192945 \nL 335.294464 163.144031 \nL 335.599132 153.634772 \nL 335.903801 202.449994 \nL 336.208469 188.32923 \nL 336.513137 168.229614 \nL 336.817806 167.446866 \nL 337.122474 167.374821 \nL 337.427142 185.020562 \nL 337.731811 134.330241 \nL 338.036479 177.039344 \nL 338.341147 184.313318 \nL 338.645815 178.698118 \nL 338.950484 147.558835 \nL 339.255152 185.960253 \nL 339.55982 162.356527 \nL 339.864489 175.830585 \nL 340.169157 158.899123 \nL 340.473825 166.966567 \nL 340.778494 180.432324 \nL 341.083162 153.369967 \nL 341.38783 184.608328 \nL 341.997167 152.997341 \nL 342.301835 173.961848 \nL 342.606503 165.5614 \nL 342.911172 190.811412 \nL 343.21584 145.434775 \nL 343.520508 175.205982 \nL 343.825177 185.602654 \nL 344.129845 161.971911 \nL 344.434513 176.246918 \nL 344.739182 170.489915 \nL 345.04385 196.517658 \nL 345.348518 165.467949 \nL 345.653186 148.209727 \nL 345.957855 176.511881 \nL 346.262523 156.418841 \nL 346.567191 210.749995 \nL 346.87186 176.85347 \nL 347.176528 178.528395 \nL 347.481196 178.19525 \nL 347.785865 180.488676 \nL 348.090533 214.756364 \nL 348.395201 186.463145 \nL 348.699869 185.219621 \nL 349.004538 164.706251 \nL 349.613874 194.461361 \nL 349.918543 160.801611 \nL 350.223211 164.626822 \nL 350.527879 193.582249 \nL 350.832548 142.146651 \nL 351.137216 191.145982 \nL 351.441884 194.82116 \nL 351.746553 154.082522 \nL 352.051221 146.214595 \nL 352.355889 182.748273 \nL 352.660557 166.616201 \nL 352.965226 166.599124 \nL 353.269894 175.222822 \nL 353.574562 210.882065 \nL 353.879231 165.605613 \nL 354.183899 171.434836 \nL 354.488567 186.3383 \nL 354.793236 179.929701 \nL 355.097904 138.111492 \nL 355.402572 196.968004 \nL 355.70724 180.106332 \nL 356.011909 179.346446 \nL 356.316577 155.517428 \nL 356.621245 200.107131 \nL 356.925914 166.541347 \nL 357.230582 191.467899 \nL 357.839919 173.673667 \nL 358.144587 137.780704 \nL 358.449255 165.209816 \nL 358.753924 162.625755 \nL 359.058592 186.78685 \nL 359.36326 165.973437 \nL 359.667928 181.662886 \nL 359.972597 151.108171 \nL 360.277265 161.108428 \nL 360.581933 164.300711 \nL 360.886602 174.32296 \nL 361.19127 148.297924 \nL 361.495938 144.086942 \nL 361.800607 180.069217 \nL 362.105275 190.051281 \nL 362.409943 141.516429 \nL 362.409943 141.516429 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 42.828125 224.64 \nL 42.828125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 377.628125 224.64 \nL 377.628125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 42.828125 224.64 \nL 377.628125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 42.828125 7.2 \nL 377.628125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa11b96d53d\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"42.828125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(range(len(loss_store)) ,loss_store)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(dataset, len(state_pd), shuffle=False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_nn.eval()\n",
    "for x_cont_batch, x_fac_batch , y_batch in test_dataloader :\n",
    "    logit = tabular_nn(x_cont_batch,x_fac_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.4958, -1.9882, -1.9993, -1.6830, -2.4763, -3.2397, -1.9744, -2.8495,\n",
       "         -2.0562, -1.5979, -2.0333, -1.4269, -0.8203, -3.5980, -3.0775, -1.9140,\n",
       "         -2.9665, -1.7668, -2.2052, -2.0239, -2.6634, -2.8741, -3.3897, -1.8810,\n",
       "         -2.5031, -2.2039, -2.1934, -1.1100, -2.0915, -1.5654, -2.4964, -2.6574,\n",
       "          0.0290, -1.5563, -1.4085, -2.2094, -2.2565, -2.3308, -2.0501, -1.6354,\n",
       "         -1.1710, -1.7590, -1.2748, -3.6602, -2.3688]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 239
    }
   ],
   "source": [
    "logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.topk(nn.Sigmoid()(logit), 6)[1].detach().numpy() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.sort(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   pred_number_1  pred_number_2  pred_number_3  pred_number_4  pred_number_5  \\\n",
       "0             13             28             33             35             41   \n",
       "\n",
       "   pred_number_6  \n",
       "0             43  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_number_1</th>\n      <th>pred_number_2</th>\n      <th>pred_number_3</th>\n      <th>pred_number_4</th>\n      <th>pred_number_5</th>\n      <th>pred_number_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>28</td>\n      <td>33</td>\n      <td>35</td>\n      <td>41</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 242
    }
   ],
   "source": [
    "pd.DataFrame(prediction,columns=[f\"pred_number_{i+1}\" for i in range(prediction.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     number_1  number_2  number_3  number_4  number_5  number_6\n",
       "0          10        23        29        33        37        40\n",
       "1           9        13        21        25        32        42\n",
       "2          11        16        19        21        27        31\n",
       "3          14        27        30        31        40        42\n",
       "4          16        24        29        40        41        42\n",
       "..        ...       ...       ...       ...       ...       ...\n",
       "957         2         9        10        16        35        37\n",
       "958         1        14        15        24        40        41\n",
       "959         2        18        24        30        32        45\n",
       "960        11        20        29        31        33        42\n",
       "961         1        18        28        31        34        43\n",
       "\n",
       "[962 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number_1</th>\n      <th>number_2</th>\n      <th>number_3</th>\n      <th>number_4</th>\n      <th>number_5</th>\n      <th>number_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>23</td>\n      <td>29</td>\n      <td>33</td>\n      <td>37</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>13</td>\n      <td>21</td>\n      <td>25</td>\n      <td>32</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11</td>\n      <td>16</td>\n      <td>19</td>\n      <td>21</td>\n      <td>27</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14</td>\n      <td>27</td>\n      <td>30</td>\n      <td>31</td>\n      <td>40</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>24</td>\n      <td>29</td>\n      <td>40</td>\n      <td>41</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>957</th>\n      <td>2</td>\n      <td>9</td>\n      <td>10</td>\n      <td>16</td>\n      <td>35</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>958</th>\n      <td>1</td>\n      <td>14</td>\n      <td>15</td>\n      <td>24</td>\n      <td>40</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>959</th>\n      <td>2</td>\n      <td>18</td>\n      <td>24</td>\n      <td>30</td>\n      <td>32</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>960</th>\n      <td>11</td>\n      <td>20</td>\n      <td>29</td>\n      <td>31</td>\n      <td>33</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>961</th>\n      <td>1</td>\n      <td>18</td>\n      <td>28</td>\n      <td>31</td>\n      <td>34</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n<p>962 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 243
    }
   ],
   "source": [
    "win_nums_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            1         2         3         4         5         6         7  \\\n",
       "961  0.139438  0.132154  0.133195  0.138398  0.133195  0.122789  0.131113   \n",
       "\n",
       "            8         9        10  ...       39        40        41        42  \\\n",
       "961  0.133195  0.105099  0.139438  ...  0.14256  0.144641  0.123829  0.130073   \n",
       "\n",
       "           43        44        45  year  month  Week_Number  \n",
       "961  0.146722  0.132154  0.139438    19      4           17  \n",
       "\n",
       "[1 rows x 48 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>year</th>\n      <th>month</th>\n      <th>Week_Number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>961</th>\n      <td>0.139438</td>\n      <td>0.132154</td>\n      <td>0.133195</td>\n      <td>0.138398</td>\n      <td>0.133195</td>\n      <td>0.122789</td>\n      <td>0.131113</td>\n      <td>0.133195</td>\n      <td>0.105099</td>\n      <td>0.139438</td>\n      <td>...</td>\n      <td>0.14256</td>\n      <td>0.144641</td>\n      <td>0.123829</td>\n      <td>0.130073</td>\n      <td>0.146722</td>\n      <td>0.132154</td>\n      <td>0.139438</td>\n      <td>19</td>\n      <td>4</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 244
    }
   ],
   "source": [
    "state_pd.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_table_ch = deepcopy(test_table)\n",
    "for col , scaler in encodding_scaler.items() :\n",
    "    test_table_ch[col] = test_table_ch[col].fillna(\"VV_likely\")\n",
    "    test_table_ch[col] = scaler.transform(test_table_ch[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = TabularDataset(test_table_ch , None, fac_cols)\n",
    "loader = DataLoader(dataset, len(test_table_ch), shuffle=False, num_workers=1)\n",
    "x_cont_batch, x_fac_batch , y_batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.140333  0.132017  0.133056  0.138254  0.133056  0.122661  0.130977   \n",
       "\n",
       "          8        9        10  ...        39        40        41        42  \\\n",
       "0  0.133056  0.10499  0.139293  ...  0.142412  0.144491  0.123701  0.129938   \n",
       "\n",
       "         43        44        45  year  month  Week_Number  \n",
       "0  0.147609  0.132017  0.139293  2021      5           19  \n",
       "\n",
       "[1 rows x 48 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>year</th>\n      <th>month</th>\n      <th>Week_Number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.140333</td>\n      <td>0.132017</td>\n      <td>0.133056</td>\n      <td>0.138254</td>\n      <td>0.133056</td>\n      <td>0.122661</td>\n      <td>0.130977</td>\n      <td>0.133056</td>\n      <td>0.10499</td>\n      <td>0.139293</td>\n      <td>...</td>\n      <td>0.142412</td>\n      <td>0.144491</td>\n      <td>0.123701</td>\n      <td>0.129938</td>\n      <td>0.147609</td>\n      <td>0.132017</td>\n      <td>0.139293</td>\n      <td>2021</td>\n      <td>5</td>\n      <td>19</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 328
    }
   ],
   "source": [
    "test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   pred_number_1  pred_number_2  pred_number_3  pred_number_4  pred_number_5  \\\n",
       "0             13             28             33             35             41   \n",
       "\n",
       "   pred_number_6  \n",
       "0             43  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_number_1</th>\n      <th>pred_number_2</th>\n      <th>pred_number_3</th>\n      <th>pred_number_4</th>\n      <th>pred_number_5</th>\n      <th>pred_number_6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>28</td>\n      <td>33</td>\n      <td>35</td>\n      <td>41</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 329
    }
   ],
   "source": [
    "\n",
    "logit = tabular_nn(x_cont_batch,x_fac_batch)\n",
    "prediction = torch.topk(nn.Sigmoid()(logit), 6)[1].detach().numpy() + 1\n",
    "prediction.sort(axis=1)\n",
    "best_candidate = pd.DataFrame(prediction,columns=[f\"pred_number_{i+1}\" for i in range(prediction.shape[1])])\n",
    "best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   pred_number_1  pred_number_2  pred_number_3  pred_number_4  pred_number_5  \\\n",
       "0              1             12             13             28             30   \n",
       "\n",
       "   pred_number_6  pred_number_7  pred_number_8  pred_number_9  pred_number_10  \n",
       "0             33             34             35             41              43  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_number_1</th>\n      <th>pred_number_2</th>\n      <th>pred_number_3</th>\n      <th>pred_number_4</th>\n      <th>pred_number_5</th>\n      <th>pred_number_6</th>\n      <th>pred_number_7</th>\n      <th>pred_number_8</th>\n      <th>pred_number_9</th>\n      <th>pred_number_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>12</td>\n      <td>13</td>\n      <td>28</td>\n      <td>30</td>\n      <td>33</td>\n      <td>34</td>\n      <td>35</td>\n      <td>41</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 330
    }
   ],
   "source": [
    "candidate_n = 10\n",
    "prediction = torch.topk(nn.Sigmoid()(logit), candidate_n)[1].detach().numpy() + 1\n",
    "prediction.sort(axis=1)\n",
    "candidate_number = pd.DataFrame(prediction,columns=[f\"pred_number_{i+1}\" for i in range(prediction.shape[1])])\n",
    "candidate_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    " comb = np.array(list(combinations(prediction.tolist()[0] , 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where( (comb.sum(axis=1) > 140) & (comb.sum(axis=1) <150))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = pd.DataFrame(comb[indices,],columns=[f\"pred_number_{i+1}\" for i in range(comb.shape[1])])#\n",
    "pd.concat([best_candidate,candidate],axis=0).to_csv(\"./210515_963회_추천번호.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}